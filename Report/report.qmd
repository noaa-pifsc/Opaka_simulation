---
title: "Opakapaka Simulation Report"
date: "February 24, 2026"
date-format: "MMMM D, YYYY"

authors:
  - name: "Megumi Oshima, Marc Nadon, John Syslo,<br>Hongguang Ma, Felipe Carvalho"
    affiliation: "Pacific Islands Fisheries Science Center"

toc: true
toc-title: "Table of contents"
toc-location: right
toc-depth: 2
number-sections: true

bibliography: references.bib

filters:
  - fontawesome 

format:
  #pdf: default
  html:
    toc-float: true
    embed-resources: true

execute: 
  echo: false
---

```{r}
#| label: setup
#| include: false
#| message: false
#| warning: false
library(tidyverse)
library(gt)
# renv::install("katiejolly/nationalparkcolors")
library(nationalparkcolors)
arches_colors <- nationalparkcolors::park_palette(name = "Arches", n =5)

```

[{{< fa brands github >}} GitHub Repository](https://github.com/PIFSCstockassessments/Opaka_simulation){target="_blank" .btn .btn-light}

# Introduction  
 
The crimson jobfish (*Pristipomoides filamentosus*), locally known as 'ōpakapaka, represents one of Hawaii's most culturally and economically significant deep-water bottomfish species, comprising over 50% of the total Deep-7 bottomfish catch and generating close to $1 million annually in commercial value (Luers et al., 2018). As a slow-growing, long-lived species attaining up to 43 years of age (Andrews et al., 2012) and inhabiting depths of 100-400 meters around the Main Hawaiian Islands (Luers et al., 2018), 'ōpakapaka supports both vital commercial and non-commercial fisheries that are deeply embedded in Hawaiian culture and food security. The species is currently managed under the Western Pacific Regional Fishery Management Council's Hawaii Fishery Ecosystem Plan as part of the Deep-7 bottomfish complex (Western Pacific Regional Fishery Management Council, 2009). 

The current stock assessment model for the Deep-7 complex combines all seven species together in a surplus production model that relies on combined catch and index of abundance data. A single-species model for 'ōpakapaka has been developed for research and to support the Deep 7 assessment but it has not been used for management. Because 'ōpakapaka is so dominate in the fishery, it is one of the few species out of the seven that we can build an integrated, age-structured model for. The benefit of transitioning to an integrated model is that it allows us to incorporate more data such as length or age compositions and species-specific life-history information. However, collecting the information that goes into an integrated assessment can be resource- and time-intensive. Fishery-independent surveys can provide high-quality, non-biased data that reflect the true population dynamics of targeted species, however, they can be expensive to run on an annual basis. But, if too little effort is put into the survey and the quality of the data collected is poor, it is not informative in a stock assessment model. Therefore it is important to optimize the sampling procedures of a survey to provide the most informative data while also balancing the costs and time required.  

The Bottomfish Fishery-Independent Survey in Hawai'i (BFISH) uses a stratified-random sampling design to estimate abundance of the Deep 7 bottomfish species, including 'ōpakapaka around the main Hawaiian islands. The survey has been operational since 2016 and historically involved two gear types, a remote stereo-video camera and hook-and-line research fishing. However, due to operational and financial constraints, starting in 2025, the survey only uses the research fishing gear. Sampling is conducted in 500 x 500 m primary sampling unit grids, distributed among the 24 strata types. Catch rate, fish lengths, and life-history information are collected from the individuals caught with research fishing and this data is used to develop an index of relative abundance for each species within the Deep 7 stock and the stock as a whole (#TODO: Ducharme-Barth 2024). The indices of abundance are then used in the stock assessment to inform population trends. Over the years, the number of sampled grids has fluctuated due to logistical or financial constraints. Since the number of grids has a direct impact on the precision of the information derived from the survey, it is crucial to understand the relationship between the number of grids surveyed and the impact that has on quantities estimated from the stock assessment model and used for management. Additionally, understanding the implications of alternative sampling designs may help to design more efficient sampling designs given resource constraints or potential environmental changes. 

 The objective of this project is to understand how we optimize an operational fishery-independent survey for 'ōpakapaka in the main Hawaiian islands by testing the impact of effort of the survey under two future recruitment conditions on our ability to estimate key stock quantities such as spawning stock biomass and management reference points. 

# Methods 

## Simulation Approach  
We tested the impact of varying sampling efforts of a fishery-independent survey by simulating abundance trends and data for 'ōpakapaka in the main Hawaiian islands given appropriate process and observational error. We fit the simulated data to an age-structured catch-at-age model and estimated spawning stock biomass, fishing mortality, and management reference points. Both the operating model (OM) and estimation model (EM) were built in Stock Synthesis (@methot_stock_2013) (SS3) and the simulation-estimation process was implemented using *ss3sim* (#TODO: Anderson et al 2013, 2014) in the R statistical software environment (#TODO R Core Team 2013). In total, 1,000 iterations were run using the Open Science Grid (#TODO: add citation). Each run involved (1) generating the population dynamics from the OM, with the given F and recruitment deviations timeseries, (2) sampling data with error from the OM, and (3) fitting those data in an EM. For each run, estimated quantities of interest were compared to the "true" values as calculated by the OM. All code for the analysis is available in the [GitHub repository](https://github.com/noaa-pifsc/Opaka_simulation). 

## Operating Model  

The operating model was a single-species, single-sex, age-structured model conditioned on 'ōpakapaka life history parameters and historical fishery data trends from the Deep 7 complex. Historical data included 75 years of catch, CPUE, and size data from commercial and non-commercial fisheries, plus seven years of abundance indices and length composition data from the Bottomfish Fishery-Independent Survey in Hawaii (BFISH).
The OM simulated population dynamics and generated data with observation error for 100 years. Fishing mortality time series were generated based on historical patterns: low values at fishery inception, increasing through the 1970s and remaining high until the late 1990s, then declining in the early 2000s and stabilizing through the end of the time series (@fig-F-timeseries). Annual fishing mortality values included stochastic variability (standard deviation of 0.002) to introduce realistic variation between iterations. Following the most recent Deep 7 benchmark stock assessment, we applied time-varying ratios for non-commercial catch: 1.94 from 1948-2003 and 1.09 for 2004-2049 (#TODO add citation for deep7 assessment). 

```{r}
#| message: false
#| label: fig-F-timeseries
#| fig-cap: Fishing mortality time series for the commercial (blue lines) and non-commercial (orange lines) fisheries.
load("../Inputs/constantF_mat.RData")

comm <- F_comm_df %>% 
as.data.frame() %>% 
mutate(Year = seq(1949, 2048), 
Fishery = "Commercial") %>%
pivot_longer(cols = -c("Year", "Fishery"), values_to = "Fishing Mortality") %>%
mutate(number = as.numeric(str_remove(name, "V"))) 

noncomm <- F_noncomm_df %>% 
as.data.frame() %>% 
mutate(Year = seq(1949, 2048), 
Fishery = "Non-Commercial") %>%
pivot_longer(cols = -c("Year", "Fishery"), values_to = "Fishing Mortality") %>%
mutate(number = as.numeric(str_remove(name, "V"))) 

comm %>% 
bind_rows(noncomm) %>%
ggplot(aes(x = Year, y = `Fishing Mortality`)) + 
geom_line(aes(group = interaction(number, Fishery), color = Fishery), alpha = .65) +
stockplotr::theme_noaa() +
  scale_colour_manual(
  values = nationalparkcolors::park_palette(name = "Arches", n=2), 
  name = "Fishery"
  ) 

```

### Recruitment Deviations

The simulation framework was structured to evaluate estimation model performance under varying future conditions. The first 75 years of the 100-year simulation represented the historical period with known data patterns, while the final 25 years constituted "future years" designed to test the robustness of the estimation model against potential changes in recruitment dynamics. Two distinct recruitment scenarios were implemented for these future years to bracket plausible recruitment conditions: (1) a "normal" recruitment scenario that maintained historical mean recruitment levels with no systematic change over time, and (2) a "poor recruitment" scenario that imposed a 40% decline in mean recruitment relative to historical levels. This approach allowed us to assess whether survey sampling intensity affects the estimation model's ability to detect and respond to recruitment shifts that could significantly impact stock productivity and sustainable harvest levels. A total of 200 recruitment deviation time series were generated, 100 were independent, bias-corrected lognormal random deviates with a standard deviation ($σ_R$) of 0.52 for the entire 100 years, and the remaining 100 were the same for the first 75 years and then the last 25 years were calculated to drive a decline in recruitment.

The recruitment decline scenario was structured as a two-phase process spanning 25 years. The first phase consisted of a 10-year gradual decline period, during which recruitment decreased from baseline levels to 60% of the historical mean. The annual decline rate (*r*) was calculated as:
$$
r = (r_{reduced}^(\frac{1}{10})) - 1
$$
where *r~reduced~* is the proportion by which the stock was reduced. Because of the non-linear relationship between spawning biomass and recruitment, the reduced level did not actually need to be 60%. We used an iterative process to determine what reduced proportion actually resulted in 60% of the mean recruitment (*r~reduced~* = 0.71). 
This formulation ensured a smooth exponential decline reaching the target reduction after 10 years. The second phase maintained recruitment at the reduced level (60% of baseline) for an additional 15 years, representing a new regime of lower recruitment conditions.

The baseline recruitment level was established using the mean recruitment from the most recent 15-year period (280,000 individuals), representing contemporary recruitment conditions prior to the simulated decline. 

For the decline phase, annual multipliers were calculated as:
$$
M_t = (1 + r)^t
$$

where *t* represents the ten years of the decline. For the lower recruitment regime period (years 11-25), multipliers were set to *r~reduced~*, maintaining recruitment at 60% of baseline levels.

Projected recruitment levels were converted to recruitment deviations in log-space to maintain consistency with stock assessment model parameterization. Base recruitment deviations were calculated as:

$$
δ_t = ln(\frac{R_t}{R̄}) - \frac{{σ_R}^2}{2}
$$

where *R~t~* represents projected recruitment in year *t*, *R̄* is the baseline mean recruitment (279.67), and $σ_R$ is the recruitment variability parameter (0.52). The bias correction term $(σ_R^2 / 2)$ accounts for the Jensen's inequality effect when transforming between arithmetic and log scales.

To incorporate realistic recruitment variability around the deterministic decline trend, we generated 100 Monte Carlo iterations of the poor recruitment time series. For each iteration, recruitment deviations were modified by adding random noise drawn from a normal distribution with mean = 0 and standard deviation = 0.15. This additional variability was intentionally set smaller than the base recruitment variability ($σ_R$ = 0.52) to ensure the underlying decline signal remained detectable above the noise.

The final recruitment deviations for each iteration *i* were calculated as:
$$
δ_{t,i} = δ_t + ε_{t,i}
$$

where $ε_{t,i} \sim N(0, 0.15²)$.

```{r}
#| message: false
#| label: fig-rec_dev
#| fig-cap: Log recruitment deviations for one iteration used in the normal (blue line) and poor (orange line) recruitment scenarios.
 ts_df <- read.csv("../all_scens_ts.csv")

ts_df %>%
filter(model_run == "om" & str_detect(scenario, "IRF_") & iteration == 14) %>%
mutate(scenario = factor(scenario, levels = c("IRF_SQ_25_yrfwd", "IRF_poorrec_25_yrfwd"))) %>% 
ggplot() + 
geom_hline(yintercept = 0, linewidth = 1.2, color = "grey60") +
geom_line(aes(x = year, y = rec_dev, group = scenario, color = scenario), linewidth = 1.3) +
labs(x = "Year", y = "Log Recruitment Deviation") + 
stockplotr::theme_noaa() +
scale_colour_manual(
  values = nationalparkcolors::park_palette(name = "Arches", n=2), 
  name = "Recruitment Scenario", labels = c("Normal", "Poor")
  ) 

```

### Initial Fishing Mortality and Selectivity

Initial fishing mortality was fixed at 0.012 for the commercial fishery and assumed to start at equilibrium for the non-commercial fishery. Logistic selectivity was modeled for the commercial and non-commercial fisheries and a dome-shaped double normal selectivity model was used for the research fishing survey (@fig-selex). 

```{r}
#| warning: false
#| message: false
#| label: fig-selex
#| fig-cap: Selectivity functions used for the commercial (blue line), non-commercial (orange line), and survey (red line).
rep <- r4ss::SS_output(dir = "../models/02_Opaka_BFISH_simulation_EM", verbose = F, printstats=FALSE)

rep$sizeselex %>% 
filter(Yr == 2023 & Factor == "Lsel") %>%
select(-c("Factor", "Yr", "Sex", "Label")) %>%
pivot_longer(cols = -Fleet, names_to = "Length", values_to = "Selectivity") %>%
mutate(Length = as.numeric(Length),
Fleet = case_when(
  Fleet == 1 ~ "Commercial",
  Fleet == 2 ~ "Non Commercial",
  Fleet == 3 ~ "Survey"
)) %>%
ggplot(aes(x = Length, y = Selectivity)) +
geom_line(aes(color = Fleet), linewidth = 1.5) + 
stockplotr::theme_noaa() +
scale_colour_manual(values = nationalparkcolors::park_palette(name = "Arches", n=3)) 
```


### Data Generation  

We evaluated five sampling scenarios to assess how different levels of survey effort affect stock assessment performance under each recruitment condition (@tbl-sas). Survey effort was defined by the number of sampling grids covered, which directly influenced the precision of the resulting abundance index and length composition data. Catch, CPUE, and length composition data were simulated from the OM based on the population dynamics generated by the specific F and recruitment deviation time series (@fig-data). 

**Survey Effort Scenarios**  
The scenarios ranged from high survey effort (HSE) with 632 grids to extra low survey effort (XLSE) with only 257 grids. As expected, higher effort translated to more precise data: index CVs ranged from 15% (HSE) to 30% (XLSE), and effective sample sizes for length compositions ranged from 60 (HSE) to 15 (XLSE). The no survey effort scenario (NSE) represented a baseline case where stock assessments would rely solely on fishery-dependent data.

```{r}
#| label: tbl-sas
#| tbl-cap: "The observational error used to sample data from the OM for high survey effort (HSE), intermediate survey effort (ISE), low survey effort (LSE), extra low survey effort (XLSE), and no survey effort (NSE). For each survey effort, the number of sampling grids (Grids) that effort would translate to, the resulting index of abundance CV, and effective sample size for length composition data are shown. All sampling effort scenarios were tested under both normal and poor recruitment conditions."
 
sas <- read.csv("sas.csv")

CV <- c(.24, .18, .15, .3)
# equation based on fitting linear regression to Model-based CV for resfish ~ # resfish grids for years 2018-2022
x <- (CV - 0.4027)/-0.0004

sas_table <- sas %>% 
select(-c(N_years, F_scen, Resfish_sd_obs, Recruitment)) %>%
mutate(
    Scen_name = str_remove(Scen_name, "_SQ"),
    Scen_name = str_remove(Scen_name, "_poorrec"),
    N_grids = c(0,0,407,407,557,557,632,632,557,557,257,257)) %>% 
    filter(str_detect(Scen_name, "Selex", negate = TRUE)) %>%
distinct(Scen_name, .keep_all = T) %>%
select(Scen_name, N_grids, Resfish_index_CV, Neff_len_Resfish) %>%
mutate(Scen_name = factor(Scen_name, levels = c("NSE", "XLSE", "LSE", "ISE", "HSE"))) %>%
  arrange(Scen_name)

knitr::kable(sas_table,
             col.names = c("Sampling Effort", "Grids", "CV", "effN"),
             align = "lccc") %>%
  kableExtra::kable_styling(bootstrap_options = c("condensed", "hover"),
                           full_width = FALSE,
                           position = "center",
                           font_size = 12)
```

**Data Sources by Scenario**  
All scenarios had some combination of catch, abundance index, and length composition data available for the EM (@fig-data). For all survey scenarios (HSE through XLSE), commercial CPUE and length data were discontinued after 2023, forcing the estimation model to rely entirely on survey-based abundance and length data for the final 25 years. This design allowed us to isolate the effect of survey data quality on assessment performance. In contrast, the NSE scenario continued using commercial fishery data throughout the entire time series.

```{r}
#| message: false
#| warning: false
#| fig-width: 8
#| fig-height: 12
#| label: fig-data
#| fig-cap: "Data generated from operating models and used in the estimation models with the survey (a) and the estimation models without the survey (b). The size of each point represents the relative amount of data available per year and fleet (i.e. large points represent years with more data)."
#include figure to show type/amount of data for each scenario
reps <- r4ss::SSgetoutput(
  dirvec = c("../FRSonly_SQ_25_yrfwd/1/em",
  "../HRF_SQ_25_yrfwd/1/em"))

# Create custom layout with larger plots
layout(matrix(c(2,1), nrow = 2), widths = c(1), heights = c(2,2))
par(mar = c(5,4,4,2))

# First plot
r4ss::SSplotData(reps$replist1, subplots = 2, 
                 fleetcol = c(arches_colors[1], arches_colors[2]), 
                 fleetnames = c("Commercial", "Non Commercial"))
title("b) Without survey", adj = 0, font.main = 2)

# Second plot
r4ss::SSplotData(reps$replist2, subplots = 2, 
                 fleetcol = c(arches_colors[1], arches_colors[2], arches_colors[3]), 
                 fleetnames = c("Commercial", "Non Commercial", "Survey"))
title("a) With survey", adj = 0, font.main = 2)
```


**Hyperstability in Fishery Data**  
For the NSE scenario under poor recruitment conditions, we incorporated hyperstability into the commercial CPUE data to reflect realistic fishery behavior during population decline. The CPUE and catch data were modified to not fully reflect the underlying population decline, simulating the tendency of commercial fisheries to maintain catch rates even as fish abundance decreases through improved fishing efficiency, targeting behavior, or fishing in higher-density areas.

**Observation Error Specification**  
Sampling error (variability in data sampled from the OM) and observation error specified in the EM were the same, ensuring no misspecification of uncertainty. The CV and effective sample size parameters remained constant across all years within each scenario (@tbl-sas).


## Estimation Model  
The only structural difference in the EM from the OM was that for the poor recruitment condition, a recruitment regime time block was introduced for the last 15 years. Without the regime, the model was unable to fit the persistant decline in recruitment and the relative errors in outputs were over exaggerated. When fitting the model, all parameters were fixed except for $R_0$, the regime parameter for the poor recruitment scenarios, catchability for the commercial and survey fleets, and selectivity parameters for the commercial fishery and survey fleet. All life history and fishery relationships were fixed at their true value (as specified in the OM).

## Performance Indices  
To compare the bias and precision of each sampling strategy, we compared the relative error (RE) between the OM and EM for spawning stock biomass (SSB), fishing mortality (F), age-0 recruitment, and reference points SSB/SSB~MSST~ and F/F~MSY~. Bias was described by the median relative error (MRE)  

$$
MRE = median(\frac{EM - OM}{OM})
$$

where EM is the estimated value from the EM and OM is the true value from the OM, and precision was described by the variability in relative error across iterations. In particular, we report the bias and precision in the terminal year as this provides information on the long-term impacts of sample size on assessment and management abilities. We also evaluated the probability that the terminal year reference points (SSB/SSB~MSST~ and F/F~MSY~) were 10% greater or smaller than the true reference point values.   

# Results  

:::{.callout-note icon=false}
## Key results 

### Normal Recruitment Conditions  {.unnumbered}

* All sampling strategies (including no survey effort) showed similar bias for SSB and F estimates (MRE 2-3.6% for SSB, -2.4% to -3.3% for F)  
* While bias remained similar, variability increased substantially as sampling effort decreased, with relative error for SSB in the XLSE scenario ranging from -30% to 54% 
* Terminal year F and F/F~MSY~ estimates showed greater sensitivity to extremely low sampling effort (XLSE) compared to SSB-based metrics  
* Persistent overestimation of recruitment led to optimistic bias in SSB estimates across all scenarios

### Poor Recruitment Conditions  {.unnumbered}

* NSE scenario showed dramatically higher error rates (42% MRE for SSB) compared to other scenarios (7.5-10% MRE)  
* Performance gaps between high and low/no effort scenarios widened substantially under recruitment failure  
* All models failed to accurately capture poor stock conditions, with most runs showing overly optimistic stock status estimates (interquartile ranges rarely included true values)  
* While NSE captured true F/FMSY values more often, it came with much wider uncertainty ranges, potentially leading to management overreactions  

:::

Out of 1,000 EM runs, 8 runs did not converge (maximum gradient was greater than 1e-4). The EM with NSE under poor recruitment conditions had the lowest convergence rate with four iterations that did not converge but overall, model convergence for all sampling scenarios was high. 

## Normal Recruitment Conditions 

We found that under normal recrutiment conditions, all sampling strategies were similiarly biased and precise in the terminal year for SSB (@tbl-re-term-yr). RE for the terminal year ranged from 2% (standard deviation of 0.154) to 3.6% (standard deviation of 0.136). Even the scenario where there was no survey effort and just the commercial fishery CPUE and length data, MRE was almost equivalent to the highest effort scenario (@tbl-re-term-yr). This was likely due to the length of the CPUE time series and the effective sample sizes of the length data from the fishery that was available to the model in the NSE scenario. With the exception of the NSE scenario, precision around SSB in the last 25 years decreased with decreasing sampling effort (@fig-mre). The XLSE had the largest variability of relative error, ranging between -30% and 54% from the true SSB, whereas HSE RE ranged between -19% and 39% away from the true SSB. (#TODO: should I report like this or should it be based on the 95th percentile to match the figure? then that would be more like between -22%-38% for XLSE and -12%-28% for HSE.) This discrepency can have large impacts on reference point estimation. 


```{r}
ts_re <- read.csv("ts_re.csv")
```


```{r}
#| label: tbl-re-term-yr
#| message: false
#| tbl-cap: "Median relative error and standard deviation of relative error in the terminal year for spawning biomass, recruitment, and fishing mortality by scenario."
ts_re %>%
filter(year <= 2048 & str_detect(scenario, "Selex", negate = T)) %>%
group_by(scenario, year) %>%
summarise(
  SpawnMed = quantile((SpawnBio_re), 0.5, na.rm = TRUE),
  SpawnSD = sd(SpawnBio_re),
  RecruitMed = quantile((Recruit_0_re), 0.5, na.rm = TRUE),
  RecruitSD = sd(Recruit_0_re),
  FMed = quantile((F_1_re), 0.5, na.rm = TRUE),
  FSD = sd(F_1_re)) %>% 
  separate(col = scenario, into = c("scen", "Rec_scenario", "25", "Yrs"), sep = "_",
remove = F) %>% 
mutate(Rec_scenario = ifelse(Rec_scenario == "poorrec", "Poor Recruitment", "Normal Recruitment")) %>%
filter(year == max(year)) %>%
mutate(
    scen = case_when(
      scen == "FRSonly" ~ "NSE",
      scen == "HRF"     ~ "HSE",
      scen == "IRF"     ~ "ISE",
      scen == "LRF"     ~ "LSE",
      scen == "XLRF"    ~ "XLSE"
    ),
    `Spawning Biomass`  = sprintf("%.3f (%.3f)", SpawnMed, SpawnSD),
    `Recruitment`       = sprintf("%.3f (%.3f)", RecruitMed, RecruitSD),
    `Fishing Mortality` = sprintf("%.3f (%.3f)", FMed, FSD),
    scen = factor(scen, levels = c("NSE", "XLSE", "LSE", "ISE", "HSE"))
  ) %>%
  arrange(Rec_scenario, scen) %>%
  ungroup() %>%
  select(scen, Rec_scenario, `Spawning Biomass`, `Fishing Mortality`, `Recruitment`) %>%
  gt(groupname_col = "Rec_scenario") %>%
  cols_label(
    scen = "Scenario"
  ) %>%
  # tab_spanner(
  #   label = "Median RE (SD)",
  #   columns = c(`Spawning Biomass`, `Recruitment`, `Fishing Mortality`)
  # ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_row_groups()
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_options(
    row_group.background.color = "#f0f0f0",
    table.border.top.style = "solid",
    table.border.bottom.style = "solid"
  )
```

(#TODO: show only 25 year projection period? and keep 95th percentile intervals to show variability?)
```{r}
#| label: fig-mre
#| message: false
#| warning: false
#| fig-cap: "Timeseries of median (line) and 95% quantile (band) relative error of spawing stock biomass for the high (HSE), intermediate (ISE), low (LSE), extra low (XLSE), and no survey effort (NSE) scenarios under both the normal and poor recruitment conditions."

ts_re %>%
filter(year <= 2048 & str_detect(scenario, "Selex", negate = T)) %>%
group_by(scenario, year) %>% 
summarise(med_re = quantile((SpawnBio_re), 0.5, na.rm = TRUE),
uci = quantile((SpawnBio_re), .975, na.rm = TRUE),
lci = quantile((SpawnBio_re), .05, na.rm = TRUE)
) %>% 
separate(col = scenario, into = c("scen", "Rec_scenario", "25", "Yrs"), sep = "_",
remove = F) %>% 
mutate(Rec_scenario = ifelse(Rec_scenario == "poorrec", "Poor Recruitment", "Normal Recruitment")) %>%
filter(year > 2023) %>%
ggplot() +
geom_hline(yintercept = 0, color = "grey60") +
geom_ribbon(aes(x = year, ymin = lci, ymax = uci, fill = scen, color = scen), 
alpha = .25, linewidth = .5) + 
geom_line(aes(x = year, y = med_re, color = scen), linewidth = 1.2) +
facet_wrap(~ Rec_scenario) + 
labs(x = "Year", y = "SSB Relative Error") + 
stockplotr::theme_noaa() +
  scale_colour_manual(
    values = arches_colors,
    name = "Sampling Scenario", 
    labels = c("NSE", "HSE", "ISE", "LSE", "XLSE")
  ) +
  scale_fill_manual(
    values = arches_colors,
    name = "Sampling Scenario", 
    labels = c("NSE", "HSE", "ISE", "LSE", "XLSE")
  )

```


We found that fishing mortality also had similar bias and precision in the terminal year for all scenarios, however the bias was negative (estimates were slightly under estimated when compared to the true values). Terminal year F MRE ranged between -2.4% (standard deviation of 0.151) and -3.3% (0.103) (@tbl-re-term-yr). While bias was lowest in the termnial year under the XLSE scenario, the precision was the lowest for that scenario. Whereas the HSE which had highest bias, had higher precision. This makes sense that with a higher sampling effort, we would increase the precision around our estimates, however, we should be cautious as it could be slightly more biased. Similarly to SSB, with the exception of the NSE scenario, precision around F in the last 25 years decreased with decreasing sampling effort (@fig-Fmre). XLSE had the largest variability in RE, ranging from -34% to 42% and HSE had the smallest amount of variability ranging from -28% to 24% RE. (#TODO: 95th percentile range -23%-31% for XLSE, vs -18%-18% for HSE) 

#TODO: Not sure where to move this to: This was likely due to the exclusion of fishery CPUE and length data for those years and the short overlap of time between the survey and fishery data. 

```{r}
#| label: fig-Fmre
#| message: false
#| warning: false
#| fig-cap: "Timeseries of median (line) and 95% interval (band) relative error of fishing mortality for the high (HSE), intermediate (ISE), low (LSE), extra low (XLSE), and no survey effort (NSE) scenarios under both the normal and poor recruitment conditions."

ts_re %>%
filter(year <= 2048 & str_detect(scenario, "Selex", negate = T)) %>%
group_by(scenario, year) %>% 
summarise(med_re = quantile((F_1_re), 0.5, na.rm = TRUE),
uci = quantile((F_1_re), .975, na.rm = TRUE),
lci = quantile((F_1_re), .05, na.rm = TRUE)
) %>% 
filter(year > 2023) %>%
separate(col = scenario, into = c("scen", "Rec_scenario", "25", "Yrs"), sep = "_",
remove = F) %>% 
mutate(Rec_scenario = ifelse(Rec_scenario == "poorrec", "Poor Recruitment", "Normal Recruitment")) %>%
ggplot() +
geom_hline(yintercept = 0, color = "grey60") +
geom_ribbon(aes(x = year, ymin = lci, ymax = uci, fill = scen, color = scen), 
alpha = .25, linewidth = .5) + 
geom_line(aes(x = year, y = med_re, color = scen), linewidth = 1.2) +
facet_wrap(~ Rec_scenario) + 
labs(x = "Year", y = "F Relative Error") + 
stockplotr::theme_noaa() +
  scale_colour_manual(
    values = arches_colors,
    name = "Sampling Scenario", 
    labels = c("NSE", "HSE", "ISE", "LSE", "XLSE")
  ) +
  scale_fill_manual(
    values = arches_colors,
    name = "Sampling Scenario", 
    labels = c("NSE", "HSE", "ISE", "LSE", "XLSE")
  )

```


We found that over the last 25 years, the HSE and ISE best estimated the true age-0 recruitment of the population over and the XLSE scenario estimated the true age-0 recruitment the worst, particularly in the last few years (@fig-recmre). However, when looking just at the terminal year, XLSE actually had the lowest MRE (@tbl-re-term-yr), but terminal year recruitment estimates are known to be unreliable because of the nature of the way it is estimated. The persistent over estimation of age-0 recruitment for all models helps to explain the positive bias in SSB over time, particularly in the last few years of the simulation. Noteably, the variability in RE for all scenarios was much larger for recruitment than for SSB or F (@tbl-re-term-yr), suggesting the EM's ability to estimate recruitment was very poor.   

```{r}
#| label: fig-recmre
#| message: false
#| warning: false
#| fig-cap: "Timeseries of median (line) and 95% interval (band) relative error of age-0 recruitment for the high (HSE), intermediate (ISE), low (LSE), extra low (XLSE), and no survey effort (NSE) scenarios under both the normal and poor recruitment conditions."

ts_re %>%
filter(year <= 2048 & str_detect(scenario, "Selex", negate = T)) %>%
group_by(scenario, year) %>% 
summarise(med_re = quantile((Recruit_0_re), 0.5, na.rm = TRUE),
uci = quantile((Recruit_0_re), .975, na.rm = TRUE),
lci = quantile((Recruit_0_re), .05, na.rm = TRUE)
) %>% 
filter(year > 2023) %>%
separate(col = scenario, into = c("scen", "Rec_scenario", "25", "Yrs"), sep = "_",
remove = F) %>% 
mutate(Rec_scenario = ifelse(Rec_scenario == "poorrec", "Poor Recruitment", "Normal Recruitment")) %>%
ggplot() +
geom_hline(yintercept = 0, color = "grey60") +
geom_ribbon(aes(x = year, ymin = lci, ymax = uci, fill = scen, color = scen), 
alpha = .25, linewidth = .5) + 
geom_line(aes(x = year, y = med_re, color = scen), linewidth = 1.2) +
facet_wrap(~ Rec_scenario) + 
labs(x = "Year", y = "Age-0 Recruitment Relative Error") + 
stockplotr::theme_noaa() +
  scale_colour_manual(
    values = arches_colors,
    name = "Sampling Scenario", 
    labels = c("NSE", "HSE", "ISE", "LSE", "XLSE")
  ) +
  scale_fill_manual(
    values = arches_colors,
    name = "Sampling Scenario", 
    labels = c("NSE", "HSE", "ISE", "LSE", "XLSE")
  )

```


Under normal recruitment conditions, all models were biased similarly when estimating the stock status (SSB/SSB~MSST~ and F/F~MSY~) however, there was a noticable decrease in precision as sampling effort decreased (@fig-refpoints). The only exception was the NSE scenario, where stock status was well estimated with similar bias and precision to the HSE scenario. The median relative error of SSB/SSB~MSST~ ranged between 2.3% and 4% across the five scenarios (@tbl-refpoints). Precision, in terms of standard deviation, ranged from 0.1 to 0.153, where NSE scenario had the highest precision (lowest SD) and XLSE had the lowest precision (highest SD). HSE had a similar precision to NSE, at 0.109. The difference between XLSE and HSE was approximately 4 percentage points, which could be an important difference when deciding management actions. The median relative error of F/F~MSY~ for all scenarios was very close, ranging between 2.8% and 3.1% (@tbl-refpoints). There was a larger range in standard deviations though, with again about a 4 percentage point difference between the HSE and XLSE scenarios. This suggests that all sampling scenarios can get you a similar estimate of terminal year F/F~MSY~, however, lower sampling effort will decrease the precision of those estimates and increase the chances of under- and overestimating the true F/F~MSY~. 

Lastly, the probability of estimating key reference point values more than 10% off from the true value (above or below), is generally decent for all scenarios under normal recruitment conditions (@tbl-prob-wrong). The likelihood of incorrectly estimating SSB/SSB~MSST~ was less than 50% for almost all sampling scenarios, only LSE was slightly higher at 51%, and as low as 30% for NSE scenario. The likelihood of incorrectly estimating F/F~MSY~ was also less than 50% for all scenarios, and as low as 29% for NSE. In general, under normal recruitment, all sampling efforts are able to estimate stock status reference points with 10% of the true value.

```{r}
#| message: false
#| warning: false
#| label: fig-refpoints
#| fig-cap: Distirbution of relative error for terminal year SSB, spawning stock biomass at minimum stock size threshold (SSB_MSST), the terminal year stock status (SSB/SSB_MSST), terminal year F, FMSY, and terminal year fishing status (F/FMSY). 

ref_pt_re <- read.csv("ref_pt_re.csv")

ref_pt_re %>%
    select(c(iteration, scenario, #SpawnBio_re, annual_F_re, 
    ssb_ssbmsst_re, F_Fmsy_re)) %>%
    filter(scenario != "IRFSelex_poorrec_25_yrfwd") %>%
    rename(
        "iteration" = iteration,
        "scenario" = scenario,
        # "Terminal~Year~SSB" = SpawnBio_re,
        "SSB/SSB[MSST]" = ssb_ssbmsst_re,
        # "Terminal~Year~F" = annual_F_re,
        "F/F[MSY]" = F_Fmsy_re
    ) %>%
    pivot_longer(cols = -c(iteration, scenario)) %>%
    separate(
        col = scenario, into = c("scen", "Rec_scenario", "25", "Yrs"), sep = "_",
        remove = F
    ) %>%
    mutate(
        name = factor(name,
            levels = c(
                "SSB/SSB[MSST]", "F/F[MSY]"
            )
        ),
        Rec_scenario = ifelse(Rec_scenario == "poorrec", "Poor~Recruitment", "Normal~Recruitment")
    ) %>%
    ggplot() +
    geom_violin(aes(x = scen, y = value, fill = scen), alpha = .75, color = "grey30") +
    geom_boxplot(aes(x = scen, y = value),
                width = 0.1,
                color = "grey10",
                fill = "grey40",
                outlier.shape = NA) +
    stat_summary(aes(x = scen, y = value),
                fun = median,
                geom = "point",
                color = "white",
                size = 2) +
    # ggdist::stat_halfeye(aes(x = scen, y = value, fill = scen), adjust = .5, width = .6, justification = -.3, .width = 0, point_color = NA) +
    # geom_point(aes(x = scen, y = value, fill = scen, color = scen), 
    # alpha = .4, position = position_jitter(width = .25)) +
    geom_hline(yintercept = 0, color = "grey50", linetype = 2) +
    facet_grid(Rec_scenario ~ name, scales = "free_y", labeller = label_parsed) +
    scale_x_discrete(labels = NULL, breaks = NULL) +
    labs(x = "", y = "Relative Error") +
    stockplotr::theme_noaa() +
    scale_fill_manual(
        values = arches_colors,
        name = "Sampling Scenario",
        labels = c("NSE", "HSE", "ISE", "LSE", "XLSE")
    ) +
    scale_color_manual(
        values = arches_colors,
        name = "Sampling Scenario",
        labels = c("NSE", "HSE", "ISE", "LSE", "XLSE")
    ) + 
    theme(legend.position="bottom")

```

```{r}
#| label: tbl-refpoints
#| tbl-cap: "Median relative error and standard deviation of relative error in the terminal year for SSB/SSB~MSST~ and F/F~MSY~ by scenario."
ref_pt_re %>% 
  filter(scenario != "IRFSelex_poorrec_25_yrfwd") %>%
  group_by(scenario) %>%
  summarise(
    ssb_ssbmst_med = quantile(ssb_ssbmsst_re, .5, na.rm = TRUE), 
    ssb_ssbmst_sd = sd(ssb_ssbmsst_re, na.rm = TRUE),
    f_fmsy_med = quantile(F_Fmsy_re, .5, na.rm = TRUE),
    f_fmsy_sd = sd(F_Fmsy_re, na.rm = TRUE)
  ) %>%
  separate(col = scenario, into = c("scen", "Rec_scenario", "25", "Yrs"), sep = "_", remove = F) %>% 
  mutate(Rec_scenario = ifelse(Rec_scenario == "poorrec", "Poor Recruitment", "Normal Recruitment")) %>%
  mutate(
      scen = case_when(
        scen == "FRSonly" ~ "NSE",
        scen == "HRF"     ~ "HSE",
        scen == "IRF"     ~ "ISE",
        scen == "LRF"     ~ "LSE",
        scen == "XLRF"    ~ "XLSE"
      ),
      `SSB/SSB[MSST]`  = sprintf("%.3f (%.3f)", ssb_ssbmst_med, ssb_ssbmst_sd),
      `F/F[MSY]`       = sprintf("%.3f (%.3f)", f_fmsy_med, f_fmsy_sd),
      scen = factor(scen, levels = c("NSE", "XLSE", "LSE", "ISE", "HSE"))
    ) %>%
  arrange(Rec_scenario, scen) %>%
  ungroup() %>%
  select(scen, Rec_scenario, `SSB/SSB[MSST]`, `F/F[MSY]`) %>%
  gt(groupname_col = "Rec_scenario") %>%
  cols_label(
    scen = "Scenario"
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_row_groups()
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_options(
    row_group.background.color = "#f0f0f0",
    table.border.top.style = "solid",
    table.border.bottom.style = "solid"
  ) %>%
  cols_label(
    scen = "Scenario",
    `SSB/SSB[MSST]` = md("SSB/SSB~MSST~"),
    `F/F[MSY]`      = md("F/F~MSY~")
  )


```

```{r}
#| label: tbl-prob-wrong
#| tbl-cap: "Probability that reference points SSB/SSB~MSST~ and F/F~MSY~ are above or below 10% from the true value for each scenario."
ref_pt_re %>% 
  filter(scenario != "IRFSelex_poorrec_25_yrfwd") %>%
  group_by(scenario) %>%
  summarise(
    p_ssb_ssbmsst_wrong = round(mean(abs(ssb_ssbmsst_re) > 0.1, na.rm = TRUE),2),
    p_f_fmsy_wrong = round(mean(abs(F_Fmsy_re) > 0.1, na.rm = TRUE),2)
  ) %>%
  separate(col = scenario, into = c("scen", "Rec_scenario", "25", "Yrs"), sep = "_", remove = F) %>% 
  mutate(Rec_scenario = ifelse(Rec_scenario == "poorrec", "Poor Recruitment", "Normal Recruitment"),
    scen = case_when(
      scen == "FRSonly" ~ "NSE",
      scen == "HRF"     ~ "HSE",
      scen == "IRF"     ~ "ISE",
      scen == "LRF"     ~ "LSE",
      scen == "XLRF"    ~ "XLSE"
    ),
      scen = factor(scen, levels = c("NSE", "XLSE", "LSE", "ISE", "HSE"))
    ) %>%
  arrange(Rec_scenario, scen) %>%
  ungroup() %>%
  select(scen, Rec_scenario, p_ssb_ssbmsst_wrong, p_f_fmsy_wrong) %>%
  gt(groupname_col = "Rec_scenario") %>%
  cols_label(
    scen = "Scenario",
    p_ssb_ssbmsst_wrong = md("SSB/SSB~MSST~"),
    p_f_fmsy_wrong      = md("F/F~MSY~")
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_row_groups()
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_options(
    row_group.background.color = "#f0f0f0",
    table.border.top.style = "solid",
    table.border.bottom.style = "solid"
  ) 

```

## Poor Recruitment Conditions 

 When tested under poor recruitment conditions, we found that most scenarios performed similarly to each other in terms of bias and precision for SSB (@fig-mre) and F (@fig-Fmre). However compared to normal recruitment scenarios, the models performed worse in terms of both bias and precision. The notable exception was the NSE scenario. Under poor recruitment, the model performed much worse than any of the other sampling effort scenarios, with a MRE of 42% for terminal year SSB (standard deviation of .209) (@tbl-re-term-yr). However, this is not surprising due to the hyperstability of the CPUE data introduced in this scenario. The MRE for all other scenarios ranged from 7.5% (standard deviation of 0.109) to 10.2% (standard deviation of 0.162).   

We found that under poor recruitment conditions, most scenarios performed slightly worse when estimating F compared to under normal recruitment conditions (@fig-Fmre). MRE ranged from -7.1% (standard deviation of 0.101) under HSE, to -9.7% (standard deviation) under XLSE (@tbl-re-term-yr). Interestingly, the NSE scenario performed the best for estimating F in the last ten years or so. However, the variability of F estimates in this scenario is much greater over the entire projection period, and in particular the last ten years.  

Age-0 recruitment esitmates were fairly well estimated in all scenarios except NSE (@fig-recmre). Terminal year age-0 recruitment estimates were less biased in the poor recruitment conditions than they were under normal recruitment recruitment (@tbl-re-term-yr). Additionally the precision was much higher for all scenarios, including NSE over the entire projection period (@fig-recmre).

When evaluating the performance of estimating stock status reference points, we found that the HSE and ISE scenarios perform the best for terminal year SSB/SSB~MSSST~ and F/F~MSY~ (@fig-refpoints). The median relative errors are between 7% to 9% for SSB/SSB~MSST~ and -7% to -8% for F/F~MSY~ (@tbl-refpoints) and have the lowest variability. In terms of bias and precision, NSE performs the worst for terminal year SSB/SSB~MSST~, with the median relative error at 41.4%  and a standard deviation of 28%. Across the other scenarios, the range of uncertainty becomes notably wider across sampling scenarios, with the largest range under the NSE scenario. It should be noted though that the true terminal year SSB/SSB~MSST~ and F/F~MSY~ is not recovered for the majority of runs under any scenario (the interquartile range does not include 0). This suggests that under poor recruitment conditions, all of the tested models would provide an overly optimistic view of the stock status. The only exception was F/F~MSY~ under the NSE scenario, MRE for F/F~MSY~ was close to 0. However, while that scenario does capture the true value more closely, the trade-off is that the range of error is much wider than any of the other scenarios. This could lead to a greater over estimation of F/F~MSY~ which could have negative impacts on the fishery such as unnecessary reduction in allocations or closures. 

Lastly, the probability of estimating key reference point values more than 10% off from the true value (above or below), is extremely high for all scenarios under poor recruitment conditions (@tbl-prob-wrong). The likelihood of incorrectly estimating SSB/SSB~MSST~ was over 50% for all sampling scenarios and as great as 81% for NSE scenario. The likelihood of incorrectly estimating F/F~MSY~ was also greater than 50% for all scenarios except HSE, which was 48%. 

# Discussion  

:::{.callout-note icon=false}

## Key points  

* The poor recruitment condition reveals the importance of adequate sampling  
* Management reference points become more uncertain as sampling effort decreases  
* The NSE scenario suggests that it would be adequate in some situations, however, there are a few critical assumptions that would need to be considered before taking this approach  
* During periods of recruitment failure, enhanced rather than reduced monitoring may be necessary to maintain assessment reliability  
* Managers should account for increased uncertainty in stock status during periods of both poor recruitment and reduced survey effort  
* While reduced survey effort may seem economically attractive, the substantial increases in assessment uncertainty could lead to suboptimal management decisions with significant long-term costs

:::

In this simulation, we found that if normal recruitment persists in the future, the sampling effort of the fishery independent survey does not impact our ability to estimate the biomass, fishing mortality, and stock status in general, but it does increase our uncertainty around those estimates. On the other hand, we found that if recruitment were to decline in the future and a regime-type shift occurred, the survey effort impacts our ability to estimate biomass, fishing mortality, and stock status and the uncertainty around those estimates as well. Particularly, if there is no fishery-independent survey, our ability to estimate key quantities deteriorates significantly.

The poor recruitment scenario revealed critical thresholds for maintaining assessment reliability under challenging population conditions. High and intermediate survey effort scenarios (HSE and ISE) demonstrated comparable performance across all metrics, including median relative error (MRE), median absolute relative error (MARE), and the 95% confidence intervals of relative error. Lower effort scenarios (LSE and XLSE) maintained similar central tendency measures but exhibited substantially wider confidence intervals, indicating reduced precision in parameter estimates. This pattern illustrates how poor recruitment conditions amplify the negative consequences of reduced sampling effort, creating a compounding effect where assessment reliability deteriorates precisely when accurate population monitoring becomes most critical for management decisions. The performance degradation observed below intermediate effort levels suggests that survey coverage should be maintained between 550-630 grids to ensure adequate assessment quality for 'ōpakapaka stock management, particularly given the potential for unexpected recruitment variability in this system.

One interesting finding was the stark contrast of the NSE scenario performances under the two recruitment conditions. The NSE scenario's performance suggests that in some cases, no survey data may be adequate if the fishery CPUE index is accurately tracking the population trends. Having one continuous data source of good quality may be preferable to shorter time series of data or very poor quality survey data. However, this is only true under the normal recruitment conditions and once poor recruitment was introduced the model performed far worse than the others in almost every metric. A major assumption of the NSE model is that the fishery data, particularly the CPUE and size data are accurately characterizing the full population. This is likely untrue, as fishers are knowledgeable about where and when to find larger fish and will likely be able to maintain a healthy catch even if the population is declining. Therefore, we should not assume that the fishery is an accurate, unbaised representation of what is actually happening in the population.  

Our simulation relies on several key assumptions that may not fully capture the complexity of real-world fishery dynamics and data collection challenges. The NSE scenario under poor recruitment assumed complete hyperstability in fishery data, meaning catch rates remained unaffected by population decline throughout the 25-year projection period. While hyperstability is a documented phenomenon in fishery-dependent CPUE indices, sustained recruitment failure would likely eventually manifest in commercial catch data, suggesting our model may have overestimated the NSE scenario's limitations. Nevertheless, this represents a plausible worst-case scenario that highlights the risks of relying solely on fishery-dependent data during periods of stock decline. Additionally, our model simplified future data availability by excluding fishery CPUE and length composition data after 2023, which artificially increased uncertainty even in high survey effort scenarios. In practice, these fishery data streams would continue but would be appropriately weighted within the assessment framework to balance their influence against survey observations. Finally, the poor recruitment scenarios employed reduced variability in recruitment deviations to clearly establish declining trends, whereas natural recruitment variability typically remains high even during periods of average decline. This simplification may have amplified the apparent impacts of recruitment failure, as realistic variability could obscure declining trends and complicate early detection of regime shifts.

While consistent long-term monitoring remains ideal, a combination of adaptive sampling strategies and improved data collection techniques could help balance assessment reliability with resource constraints. An adaptive approach could involve reducing survey effort during periods when recruitment appears stable and population indicators show no signs of decline, then increasing sampling intensity when early warning signals suggest recruitment failure or population stress. However, such adaptive strategies must be implemented cautiously, as maintaining data continuity over extended periods provides irreplaceable value for detecting long-term trends and regime shifts. Complementary improvements to data collection could enhance assessment quality without necessarily increasing survey effort, such as incorporating annual age data from the fishery-independent survey to better understand population structure and recruitment dynamics, or refining fishing methodology to reduce coefficient of variation in catch estimates. 

These results highlight several critical considerations for fishery management. The first is that maintaining adequate survey effort is essential for reliable stock assessments, particularly for fishing mortality estimates used in management decisions. The second is that during periods of recruitment failure, enhanced rather than reduced monitoring may be necessary to maintain assessment reliability. We saw a noticeable decrease in our estimation abilities when recruitment was poor and there was a reduced survey effort. Additionally, scientists and managers should account for increased uncertainty in stock status during periods of both poor recruitment and reduced survey effort (even under normal recruitment conditions). Lastly, while reduced survey effort may seem economically attractive, the substantial increases in assessment uncertainty could lead to suboptimal management decisions with significant long-term costs for the fishery.
 